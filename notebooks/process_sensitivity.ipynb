{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### A notebook for data analysis of the sensitivity analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Specify the experiment wanted\n",
    "value_to_vary_name = \"earthquake-magnitude\"\n",
    "v = 0.32\n",
    "replications = 25\n",
    "\n",
    "# Read the pickle\n",
    "series_df = pd.read_pickle(f'../results/sensitivity/sens_series_{value_to_vary_name}_{v}_{replications}r_df.pickle')\n",
    "series_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot for one run all the variables\n",
    "series_df[\"recovered-with-help\"].plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Take the average of all the runs and plot those\n",
    "series_df_agg = series_df.groupby(level=[0], axis=\"columns\").mean()\n",
    "series_df_agg.plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Full sensitivity analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load a dictionary with the default values and if they are rounded or not\n",
    "default_values = {\n",
    "    # variable-name: (number, rounded to int or not)\n",
    "    \"call-limit\": (True, False),\n",
    "    \"earthquake-magnitude\": (0.4, False),\n",
    "    \"amount-ambulances\": (40, True),\n",
    "    \"probability-call-112\": (1, False),\n",
    "    \"amount-hospitals\": (10, True),\n",
    "    \"hospital-capacity\": (100, True),\n",
    "    \"hospital-filling-percentage-t0\": (60, False),\n",
    "    \"initial-ambulance-search-radius\": (5, True),\n",
    "    \"percentage-concrete-buildings\": (70, False),\n",
    "    \"high-damage-road-blocked-chance\": (10, False),\n",
    "    \"collapsed-road-blocked-chance\": (25, False),\n",
    "    \"max-concurrent-calls\": (50, True),\n",
    "    \"average-call-time\": (2.5, False),\n",
    "    \"amount-drones\": (10, True),\n",
    "    \"drone-speed\": (0.5, False),\n",
    "    \"drone-range\": (45, False),\n",
    "    \"ambulance-reroute-frequency\": (5, True),\n",
    "    # \"drone-view-radius\": (25, True),\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a dictionary with all the input values used\n",
    "input_values = {}\n",
    "amount_to_vary = [0.8, 1.25]\n",
    "\n",
    "for var, val in default_values.items():\n",
    "    input_values[var] = [round(val[0] * v, 5) for v in amount_to_vary]\n",
    "    if val[1]:\n",
    "        input_values[var] = [int(v) for v in input_values[var]]\n",
    "input_values[\"call-limit\"] = [True, False]\n",
    "input_values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reference = f'../results/sensitivity/sens_series_call-limit_True_{replications}r_df.pickle'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Read all the pickles into a dictionary of dataframes\n",
    "dfs = {}\n",
    "for k, vs in input_values.items():\n",
    "    for i, v in enumerate(vs):\n",
    "        dfs[(k, v)] = pd.read_pickle(f'../results/sensitivity/sens_series_{k}_{v}_{replications}r_df.pickle')\n",
    "        if i == 0:  # Add the reference df after each first value\n",
    "            dfs[(k, default_values[k][0])] = pd.read_pickle(reference)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "KPIs = list(set(dfs[('call-limit', True)].droplevel(1, axis=\"columns\").columns))\n",
    "print(KPIs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Drop first experiment run (corrupted)\n",
    "The first experiment run from each experiment is corrupted, because the input values weren't set right. Therefor they are dropped here. 24 runs remain."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for key, df in dfs.items():\n",
    "    dfs[key] = df.drop(labels=0, axis=\"columns\", level=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calculate means"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a dictionary with the means\n",
    "mean_dict = {}\n",
    "for (k, v), df_t in dfs.items():\n",
    "    mean_dict[(k, v)] = df_t.iloc[720]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mean_df = pd.DataFrame.from_dict(mean_dict).T\n",
    "mean_df = mean_df.sort_index(axis=\"columns\", level=0)\n",
    "mean_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mean_df.to_excel(\"test.xlsx\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Normalize sensitivity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mean_df_s = mean_df.T.drop(columns=\"call-limit\", level=0)\n",
    "mean_df_s"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dev_df = pd.DataFrame(index=mean_df_s.index)\n",
    "for key in list(input_values.keys())[1::]:\n",
    "    ref = mean_df_s[key].columns[1]\n",
    "    for i, column in enumerate(mean_df_s[key].columns):\n",
    "        if i != 1:\n",
    "            ratio = column/ref\n",
    "            dev_df[key, ratio] = (mean_df_s[key][column] - mean_df_s[key][ref]) / mean_df_s[key][ref]\n",
    "dev_df.columns = pd.MultiIndex.from_tuples(dev_df.columns)\n",
    "dev_df.T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "KPIs_to_drop = ['fraction-destroyed-streets-spotted', 'fraction-called-in', 'number-destroyed-streets-spotted']\n",
    "KPIs2 = [k for k in KPIs if k not in KPIs_to_drop]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_df = {}\n",
    "for k in KPIs2:\n",
    "    plot_df[k] = dev_df.T[k].stack(level=0).reset_index()\n",
    "    plot_df[k][\"level_1\"] = plot_df[k][\"level_1\"].round(2)\n",
    "plot_df[KPIs2[0]].head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2)\n",
    "fig.set_size_inches(12,5)\n",
    "g = {}\n",
    "for i, KPI in enumerate(KPIs2[:2]):\n",
    "    g[KPI] = sns.pointplot(plot_df[KPI], y=0, x=\"level_0\", hue=\"level_1\", errorbar=('ci', 95), join=False, dodge=True, ax=axes[i])\n",
    "    g[KPI].set_title(f\"Influence on {KPI}\")\n",
    "    g[KPI].set_xticklabels(g[KPI].get_xticklabels(), rotation=90)\n",
    "    g[KPI].set_xlabel(\"Variation in input value\")\n",
    "    g[KPI].set_ylabel(f\"Effect on KPI {KPI}\")\n",
    "fig.suptitle(\"Effect of variation of input values on KPIs (with 95% confidence interval)\")\n",
    "fig.savefig(\"../images/sensitivity_pointplots_1.svg\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2)\n",
    "fig.set_size_inches(12,5)\n",
    "g = {}\n",
    "for i, KPI in enumerate(KPIs2[2:]):\n",
    "    g[KPI] = sns.pointplot(plot_df[KPI], y=0, x=\"level_0\", hue=\"level_1\", errorbar=('ci', 95), join=False, dodge=True, ax=axes[i])\n",
    "    g[KPI].set_title(f\"Influence on {KPI}\")\n",
    "    g[KPI].set_xticklabels(g[KPI].get_xticklabels(), rotation=90)\n",
    "    g[KPI].set_xlabel(\"Variation in input value\")\n",
    "    g[KPI].set_ylabel(f\"Effect on KPI {KPI}\")\n",
    "fig.suptitle(\"Effect of variation of input values on KPIs (with 95% confidence interval)\")\n",
    "fig.savefig(\"../images/sensitivity_pointplots_2.svg\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Extreme values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ev_inputs = [\n",
    "    \"earthquake-magnitude\",\n",
    "    \"amount-ambulances\",\n",
    "    \"amount-hospitals\",\n",
    "    # \"drone-view-radius\",\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a dictionary with all the input values used\n",
    "ev_input_values = {}\n",
    "amount_to_vary = [0.2, 1.8]\n",
    "\n",
    "for var, val in default_values.items():\n",
    "    if var in ev_inputs:\n",
    "        ev_input_values[var] = [round(val[0] * v, 5) for v in amount_to_vary]\n",
    "        if val[1]:\n",
    "            ev_input_values[var] = [int(v) for v in ev_input_values[var]]\n",
    "ev_input_values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Read all the pickles into a dictionary of dataframes\n",
    "ev_dfs = {}\n",
    "for k, vs in ev_input_values.items():\n",
    "    for i, v in enumerate(vs):\n",
    "        ev_dfs[(k, v)] = pd.read_pickle(f'../results/sensitivity/sens_series_{k}_{v}_{10}r_df.pickle')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a dictionary with the means\n",
    "ev_mean_dict = {}\n",
    "for (k, v), df_t in ev_dfs.items():\n",
    "    ev_mean_dict[(k, v)] = df_t.iloc[720].to_dict()\n",
    "\n",
    "ev_mean_df = pd.DataFrame.from_dict(ev_mean_dict).T\n",
    "ev_mean_df.sort_index(axis=\"columns\", level=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "KPIs_to_drop = ['fraction-destroyed-streets-spotted', 'fraction-called-in', 'number-destroyed-streets-spotted']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ev_mean_df_s = ev_mean_df.drop(columns=KPIs_to_drop, axis=1, level=0).T\n",
    "ev_mean_df_s = ev_mean_df_s.sort_index(axis=\"index\", level=0)\n",
    "ev_mean_df_s"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mean_df_s2 = mean_df_s.T.drop(columns=KPIs_to_drop, axis=1, level=0).T\n",
    "mean_df_s2 = mean_df_s2.sort_index(axis=\"index\", level=0)\n",
    "mean_df_s2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "comb_mean_df = pd.concat([ev_mean_df_s, mean_df_s2], axis=1)\n",
    "comb_mean_df.sort_index(level=[1], axis=\"columns\", inplace=True)\n",
    "comb_mean_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ev_dev_df = pd.DataFrame(index=comb_mean_df.index)\n",
    "for key in list(ev_input_values.keys()):\n",
    "    ref = comb_mean_df[key].columns[2]\n",
    "    ref_mean = comb_mean_df[key][ref].mean()\n",
    "    for i, column in enumerate(comb_mean_df[key].columns):\n",
    "        ratio = column / ref\n",
    "        ev_dev_df[key, ratio] = (comb_mean_df[key][column] - comb_mean_df[key][ref]) / comb_mean_df[key][ref]\n",
    "ev_dev_df.columns = pd.MultiIndex.from_tuples(ev_dev_df.columns)\n",
    "ev_dev_df.T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,(len(ev_inputs)))\n",
    "fig.set_size_inches(16,5)\n",
    "g = {}\n",
    "for i, in_var in enumerate(ev_inputs):\n",
    "    g[in_var] = sns.lineplot(ev_dev_df[in_var].T, ax=axes[i], markers=True, errorbar=(\"ci\", 95), err_style=\"band\")\n",
    "    g[in_var].set_title(f\"Influence of {in_var} on KPIs\")\n",
    "    g[in_var].set_xlabel(\"Variation in input value\")\n",
    "    g[in_var].set_ylabel(\"Effect in output value (KPI)\")\n",
    "fig.suptitle(\"Effect of variation of input values on KPIs (with 95% confidence interval)\")\n",
    "fig.savefig(\"../images/extreme_values_plots_ci.svg\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
